{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A notebook to look how the base models perform on our data without training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import losses\n",
    "\n",
    "# Importing BERT modules\n",
    "import bert\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "from datasets import load_metric\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "import tqdm\n",
    "import pickle\n",
    "import time\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickled train and test files\n",
    "train = 'train.pkl'\n",
    "test = 'test.pkl'\n",
    "\n",
    "with open ('train.pkl', 'rb') as f:\n",
    "    df_train = pickle.load(f)\n",
    "    \n",
    "with open ('test.pkl', 'rb') as g:\n",
    "    df_test = pickle.load(g)\n",
    "    \n",
    "df_train['label'] = df_train['label'].astype(np.float64)\n",
    "df_test['label'] = df_test['label'].astype(np.float64)\n",
    "\n",
    "df_train = df_train[[\"doc_text\", \"Query\", \"label\"]]\n",
    "df_test = df_test[[\"doc_text\", \"Query\", \"label\"]]\n",
    "\n",
    "# df_val = df_val[[\"doc_text\", \"query\", \"label\"]]\n",
    "hf_train = datasets.Dataset.from_pandas(df_train)\n",
    "hf_test = datasets.Dataset.from_pandas(df_test)\n",
    "\n",
    "hf = datasets.DatasetDict({\"train\": hf_train,\n",
    "                           \"test\": hf_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "# \"cross-encoder/stsb-distilroberta-base\"\n",
    "# \"cross-encoder/qnli-electra-base\"\n",
    "\n",
    "class BaseModel:\n",
    "    def __init__(self, model_checkpoint, df_train, df_test, sentence_1_key, sentence_2_key, tokenizer):\n",
    "        self.sentence1_key = sentence_1_key #'doc_text'\n",
    "        self.sentence2_key = sentence_2_key # 'Query'\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train = df_train\n",
    "        self.test = df_test\n",
    "        \n",
    "    def preprocess_function(self, examples):\n",
    "        return self.tokenizer(str(examples[self.sentence1_key]), str(examples[self.sentence2_key]), truncation=True)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        # loss_fct = nn.BCEWithLogitsLoss()\n",
    "        loss_fct = nn.MSELoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels),labels.float().view(-1, self.model.config.num_labels))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def compute_metrics(self, eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = predictions[:, 0]\n",
    "        # fpr, tpr, thresholds = metrics.roc_curve(labels, predictions, pos_label=2)\n",
    "        return {\"auc\": metrics.roc_auc_score(y_true=labels, y_score=predictions)}\n",
    "\n",
    "    def run_base_mode(self, hf, batch_size):\n",
    "        torch.cuda.empty_cache()\n",
    "        num_labels = 1\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(self.model_checkpoint, num_labels=num_labels)\n",
    "        encoded_hf = hf.map(self.preprocess_function, remove_columns=(\"doc_text\", \"Query\"), batch_size = 512)\n",
    "\n",
    "        metric_name = \"auc\"\n",
    "        model_name = self.model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            f\"{model_name}-finetuned_auc\",\n",
    "            evaluation_strategy = \"epoch\",\n",
    "            save_strategy = \"epoch\",\n",
    "            learning_rate=2e-5,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=0,\n",
    "            weight_decay=0.01,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=metric_name,\n",
    "            push_to_hub=True,\n",
    "            eval_steps=1,\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            args,\n",
    "            train_dataset=encoded_hf[\"train\"],\n",
    "            eval_dataset=encoded_hf[\"test\"],\n",
    "            tokenizer=self.tokenizer,\n",
    "            compute_metrics=self.compute_metrics\n",
    "            # compute_loss=compute_loss\n",
    "        )\n",
    "        \n",
    "        trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cross-encoder/qnli-electra-base\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = BaseModel(\"cross-encoder/qnli-electra-base\", df_train, df_test, \"doc_text\", \"Query\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.run_base_mode(hf, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
